{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb37843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import io\n",
    "import os\n",
    "import esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "219e0596",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_read_file(file_name: os.PathLike, queue: asyncio.Queue, event_finishing: asyncio.Event, return_idx: bool = True):\n",
    "    with open(file_name, 'r') as f:\n",
    "\n",
    "        sequence_idx = 0\n",
    "        header = None\n",
    "        sequence = ''\n",
    "\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line.startswith('>'):\n",
    "                if header is None:\n",
    "                    header = line[1:].strip() \n",
    "                    \n",
    "                else:\n",
    "                    if return_idx: \n",
    "                        to_return =  (sequence_idx, header, sequence)\n",
    "                    else:\n",
    "                        to_return = (header, sequence)\n",
    "                    \n",
    "                    await queue.put(to_return)\n",
    "                    \n",
    "                    sequence_idx += 1\n",
    "                    header = line[1:].strip()\n",
    "                    sequence = '' \n",
    "                \n",
    "            else:\n",
    "                sequence += line.strip()\n",
    "                \n",
    "        event_finishing.set()\n",
    "                \n",
    "async def async_tokenize_fasta(batch_converter: esm.data.BatchConverter, in_queue: asyncio.Queue, out_queue: asyncio.Queue):\n",
    "    while True:\n",
    "        item = await in_queue.get()\n",
    "        (sequence_no, header, sequence) = item\n",
    "        data = [(header, sequence)]\n",
    "\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "        # get list of length 1 from each item\n",
    "        labels = batch_labels[0] # header\n",
    "        strs = batch_strs[0] # actual aa sequence\n",
    "        tokens = batch_tokens[0].tolist() # was torch.tensor previously\n",
    "        tokens = ' '.join(map(str, tokens)) # convert all ints to str and then map to string\n",
    "\n",
    "        await out_queue.put((labels, strs, tokens))\n",
    "        in_queue.task_done()\n",
    "        \n",
    "async def async_write_to_file(queue, f_labels: io.TextIO, f_strs: io.TextIO, f_tokens: io.TextIO):\n",
    "    while True:\n",
    "        data = await queue.get()\n",
    "        labels, strs, tokens = data\n",
    "        \n",
    "        f_labels.write(labels + '\\n')\n",
    "        f_strs.write(strs + '\\n')\n",
    "        f_tokens.write(tokens + '\\n')\n",
    "        queue.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_path = '../../../data/raw/2022-07-25_uniref/uniref50.fasta'\n",
    "first_10000 = '../../../data/raw/2022-07-25_uniref/uniref50-first10000.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_in = asyncio.Queue(maxsize=100)\n",
    "q_out = asyncio.Queue(maxsize=100)\n",
    "finish_signal = asyncio.Event() # signals to the script that we consumed the generator fully\n",
    "\n",
    "n_workers = 24\n",
    "\n",
    "creator = asyncio.create_task(read_file(fasta_path, q_in, dr)) # create a task to yield sequences from the FASTA file\n",
    "\n",
    "processor = [asyncio.create_task(async_tokenize_fasta(batch_converter, q_in, q_out)) for _ in range(n_workers)]  \n",
    "# create tasks for `n_workers` workers to tokenize the sequences from `q_in` and then put them into `q_out` for usage\n",
    "\n",
    "# file handles for writing outputs\n",
    "f_tokens = open('/work/ucsf/ntranos/variant-gsp1/tokens.txt', 'w') # tokens\n",
    "f_labels = open('/work/ucsf/ntranos/variant-gsp1/labels.txt', 'w') # headers\n",
    "f_strs = open('/work/ucsf/ntranos/variant-gsp1/headers.txt', 'w') # actual string AA sequences\n",
    "\n",
    "async_writer = asyncio.create_task(async_write_to_file(qo, f_labels, f_strs, f_tokens)) # one task to async write to file\n",
    "\n",
    "try:\n",
    "    await finish_signal.wait()\n",
    "    \n",
    "finally:\n",
    "    # when we hit here we want to clean everything up so we can \n",
    "    creator.cancel()\n",
    "    for proc in processor:\n",
    "        proc.cancel()\n",
    "    async_writer.cancel()\n",
    "    \n",
    "    for f in (f_tokens, f_labels, f_strs):\n",
    "        f.cancel()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
